{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d44166f1-f509-437c-a66e-441cc12a9fd0",
   "metadata": {},
   "source": [
    "性能测试\n",
    "RTX 4090"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3944223a-5747-405e-91cd-0ae98957c20a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Running experiment 1 / 16: res=10 m, precision=Float32, device=gpu\n",
      "▶️ Running experiment 2 / 16: res=10 m, precision=Float64, device=gpu\n",
      "▶️ Running experiment 3 / 16: res=20 m, precision=Float32, device=gpu\n",
      "▶️ Running experiment 4 / 16: res=20 m, precision=Float64, device=gpu\n",
      "▶️ Running experiment 5 / 16: res=50 m, precision=Float32, device=gpu\n",
      "▶️ Running experiment 6 / 16: res=50 m, precision=Float64, device=gpu\n",
      "▶️ Running experiment 7 / 16: res=100 m, precision=Float32, device=gpu\n",
      "▶️ Running experiment 8 / 16: res=100 m, precision=Float64, device=gpu\n",
      "✅ 所有实验完成，结果已保存到 benchmark_results.csv\n"
     ]
    }
   ],
   "source": [
    "using CUDA\n",
    "using MAT\n",
    "using LinearAlgebra\n",
    "using Random\n",
    "using Statistics\n",
    "using NPZ\n",
    "using Printf\n",
    "using Dates\n",
    "using CSV\n",
    "using DataFrames\n",
    "\n",
    "# ==== 模型参数 ====\n",
    "g_to_kg = 1e-3\n",
    "u      = 4.0\n",
    "Ry, ry = 0.306, 0.885\n",
    "Rz, rz = 0.072, 1.021\n",
    "\n",
    "domain_size = 40000  # m\n",
    "\n",
    "# ==== CUDA 核函数 ====\n",
    "function kernel_total_conc_add!(\n",
    "    C, nx, ny, dx, dy,\n",
    "    sources_x, sources_y, sources_q,\n",
    "    u, Ry, ry, Rz, rz\n",
    ")\n",
    "    ix = (blockIdx().x - 1) * blockDim().x + threadIdx().x\n",
    "    iy = (blockIdx().y - 1) * blockDim().y + threadIdx().y\n",
    "    if ix > nx || iy > ny\n",
    "        return\n",
    "    end\n",
    "\n",
    "    xpos = (ix - 1) * dx\n",
    "    ypos = (iy - 1) * dy\n",
    "\n",
    "    c = zero(eltype(C))\n",
    "    ns = length(sources_x)\n",
    "    @inbounds for k in 1:ns\n",
    "        sx = sources_x[k]\n",
    "        sy = sources_y[k]\n",
    "        q  = sources_q[k]\n",
    "\n",
    "        δy = sy - ypos\n",
    "        if δy <= 0\n",
    "            continue\n",
    "        end\n",
    "\n",
    "        σy = Ry * δy^ry\n",
    "        σz = Rz * δy^rz\n",
    "\n",
    "        term1 = q / (π * u * σy * σz)\n",
    "        term2 = exp(-((xpos - sx)^2) / (2 * σy^2))\n",
    "        c += term1 * term2\n",
    "    end\n",
    "\n",
    "    C[iy, ix] += c\n",
    "    return nothing\n",
    "end\n",
    "\n",
    "# ==== 构建源列表 ====\n",
    "function build_sources(source_map; offset_x=0.0, offset_y=0.0, T=Float32)\n",
    "    sx_list = T[]\n",
    "    sy_list = T[]\n",
    "    sq_list = T[]\n",
    "    @inbounds for j in 1:size(source_map, 2), i in 1:size(source_map, 1)\n",
    "        q_gps = source_map[i, j]\n",
    "        if q_gps == 0\n",
    "            continue\n",
    "        end\n",
    "        q = T(q_gps * g_to_kg)  # g/s → kg/s\n",
    "        push!(sx_list, T((i - 1 + rand()) + offset_x))\n",
    "        push!(sy_list, T((j - 1 + rand()) + offset_y))\n",
    "        push!(sq_list, q)\n",
    "    end\n",
    "    return (sx_list, sy_list, sq_list)\n",
    "end\n",
    "\n",
    "# ==== 模拟（只负责计算）====\n",
    "function run_simulation(full_map, res::Int, precision::DataType; device::Symbol=:gpu)\n",
    "    T = precision\n",
    "    nx = domain_size ÷ res\n",
    "    ny = nx\n",
    "\n",
    "    @assert size(full_map) == (domain_size, domain_size) \"❌ 输入尺寸应为 $(domain_size)x$(domain_size)\"\n",
    "\n",
    "    sx, sy, sq = build_sources(full_map; T=T)\n",
    "\n",
    "    if device == :gpu\n",
    "        C = CUDA.zeros(T, nx, ny)\n",
    "        threads = (16, 16)\n",
    "        blocks = (cld(nx, threads[1]), cld(ny, threads[2]))\n",
    "\n",
    "        batch_size = 1_000_000\n",
    "        total_sources = length(sx)\n",
    "        total_batches = ceil(Int, total_sources / batch_size)\n",
    "\n",
    "        for batch in 1:total_batches\n",
    "            range = (batch-1)*batch_size+1 : min(batch*batch_size, total_sources)\n",
    "            sources_x = CuArray(sx[range])\n",
    "            sources_y = CuArray(sy[range])\n",
    "            sources_q = CuArray(sq[range])\n",
    "\n",
    "            @cuda threads=threads blocks=blocks kernel_total_conc_add!(\n",
    "                C, nx, ny, T(res), T(res),\n",
    "                sources_x, sources_y, sources_q,\n",
    "                T(u), T(Ry), T(ry), T(Rz), T(rz)\n",
    "            )\n",
    "            synchronize()\n",
    "        end\n",
    "    else\n",
    "        C = zeros(T, nx, ny)\n",
    "        for ix in 1:nx, iy in 1:ny\n",
    "            xpos = (ix - 1) * res\n",
    "            ypos = (iy - 1) * res\n",
    "            c = zero(T)\n",
    "            for k in 1:length(sx)\n",
    "                δy = sy[k] - ypos\n",
    "                if δy <= 0\n",
    "                    continue\n",
    "                end\n",
    "                σy = Ry * δy^ry\n",
    "                σz = Rz * δy^rz\n",
    "                term1 = sq[k] / (π * u * σy * σz)\n",
    "                term2 = exp(-((xpos - sx[k])^2) / (2 * σy^2))\n",
    "                c += term1 * term2\n",
    "            end\n",
    "            C[iy, ix] = c\n",
    "        end\n",
    "    end\n",
    "    return C\n",
    "end\n",
    "\n",
    "# ==== Benchmark 实验 ====\n",
    "res_list = [10, 20, 50, 100]\n",
    "prec_list = [Float32, Float64]\n",
    "device_list = [:gpu]\n",
    "\n",
    "results = DataFrame(\n",
    "    exp_id=Int[],\n",
    "    resolution=Int[],\n",
    "    precision=String[],\n",
    "    device=String[],\n",
    "    compute_time_s=Float64[],\n",
    "    total_time_s=Float64[]\n",
    ")\n",
    "\n",
    "input_path = \"/root/autodl-tmp/output_sources/200m.npy\"\n",
    "\n",
    "exp_id = 0\n",
    "for res in res_list, prec in prec_list, dev in device_list\n",
    "    exp_id += 1\n",
    "    println(\"▶️ Running experiment $exp_id / 16: res=$res m, precision=$(prec), device=$dev\")\n",
    "\n",
    "    # ---- 总时间（含I/O）开始 ----\n",
    "    total_start = time_ns()\n",
    "\n",
    "    # 读输入\n",
    "    full_map = npzread(input_path)\n",
    "\n",
    "    # ---- 计算部分计时 ----\n",
    "    compute_start = time_ns()\n",
    "    C = run_simulation(full_map, res, prec; device=dev)\n",
    "    if dev == :gpu\n",
    "        CUDA.synchronize()   # 确保 GPU 完全计算完\n",
    "    end\n",
    "    compute_elapsed = (time_ns() - compute_start) / 1e9\n",
    "\n",
    "    # 写输出\n",
    "    npzwrite(\"result_$exp_id.npy\", Array(C))\n",
    "\n",
    "    # ---- 总时间（含I/O）结束 ----\n",
    "    total_elapsed = (time_ns() - total_start) / 1e9\n",
    "\n",
    "    # 存储结果\n",
    "    push!(results, (exp_id, res, string(prec), string(dev), compute_elapsed, total_elapsed))\n",
    "end\n",
    "\n",
    "CSV.write(\"benchmark_results.csv\", results)\n",
    "println(\"✅ 所有实验完成，结果已保存到 benchmark_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3cd229-5a61-4485-9e96-45a7a7a955e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.5",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
